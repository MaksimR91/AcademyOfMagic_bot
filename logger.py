import logging
from logging.handlers import TimedRotatingFileHandler
import os
import boto3
from botocore.exceptions import ClientError, EndpointConnectionError, ReadTimeoutError
from botocore.config import Config
from datetime import datetime

# ==== –ù–ê–°–¢–†–û–ô–ö–ò S3 ====
AWS_ACCESS_KEY_ID = os.getenv("YANDEX_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("YANDEX_SECRET_ACCESS_KEY")
BUCKET_NAME = "magicacademylogsars"
ENDPOINT_URL = "https://storage.yandexcloud.net"
REGION_NAME = "ru-central1"

# ==== –ü–ê–ü–ö–ê –î–õ–Ø –õ–û–ì–û–í ====
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs("tmp", exist_ok=True)  # –Ω–∞ —Å–ª—É—á–∞–π fallback-–ª–æ–≥–≥–µ—Ä–∞

# ==== S3 –ö–õ–ò–ï–ù–¢ –° –¢–ê–ô–ú–ê–£–¢–û–ú ====
s3_config = Config(connect_timeout=5, read_timeout=10)
s3_client = boto3.client(
    "s3",
    aws_access_key_id=AWS_ACCESS_KEY_ID,
    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
    endpoint_url=ENDPOINT_URL,
    config=s3_config
)

# ==== –ö–ê–°–¢–û–ú–ù–´–ô –•–≠–ù–î–õ–ï–† ====
class S3TimedRotatingFileHandler(TimedRotatingFileHandler):
    def doRollover(self):
        super().doRollover()
        timestamp = datetime.now().strftime("%Y-%m-%d")
        filename = os.path.join(LOG_DIR, f"log.{timestamp}.log")
        s3_key = f"logs/{os.path.basename(filename)}"

        logging.debug(f"[DEBUG] Uploading to S3 ‚Üí File: {filename} ‚Üí S3 Key: {s3_key}")
        try:
            s3_client.upload_file(filename, BUCKET_NAME, s3_key)
            logging.debug(f"[S3] Uploaded: {s3_key}")
        except (ClientError, EndpointConnectionError, ReadTimeoutError) as e:
            logging.warning(f"[S3 ERROR] Upload failed due to network/timeout: {e}")
        except Exception as e:
            logging.warning(f"[S3 ERROR] Unexpected error: {e}")

# ==== –§–û–†–ú–ê–¢ –õ–û–ì–û–í ====
formatter = logging.Formatter("[%(asctime)s] [%(levelname)s] %(message)s", "%Y-%m-%d %H:%M:%S")

# ==== –•–≠–ù–î–õ–ï–†–´ ====
file_handler = S3TimedRotatingFileHandler(
    os.path.join(LOG_DIR, "log"), when="midnight", interval=1, backupCount=14, encoding='utf-8'
)
file_handler.suffix = "%Y-%m-%d.log"
file_handler.setFormatter(formatter)

console_handler = logging.StreamHandler()
console_handler.setFormatter(formatter)

# ==== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –õ–û–ì–ì–ï–†–ê ====
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)
logger.addHandler(file_handler)
logger.addHandler(console_handler)

# ==== –†–ï–ó–ï–†–í–ù–´–ô BASICCONFIG, –ï–°–õ–ò –ò–ú–ü–û–†–¢–ò–†–£–ï–¢–°–Ø ====
if not logger.hasHandlers():
    logging.basicConfig(
        filename=f"tmp/logger_{datetime.now():%Y-%m-%d}.log",
        level=logging.DEBUG,
        format='%(asctime)s [%(levelname)s] %(message)s'
    )
    logging.debug("üì¶ logger.py basicConfig fallback activated")

# ==== –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê ====
def upload_to_s3_manual():
    today = datetime.now().strftime("%Y-%m-%d")
    local_path = os.path.join(LOG_DIR, f"log.{today}.log")
    s3_key = f"logs/log.{today}.log"

    logging.debug("üöÄ –ù–∞—á–∏–Ω–∞–µ–º —Ä—É—á–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –≤ S3")
    if not os.path.exists(local_path):
        logging.warning("‚ùó –õ–æ–≥-—Ñ–∞–π–ª –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–µ—á–µ–≥–æ –∑–∞–≥—Ä—É–∂–∞—Ç—å")
        return

    try:
        s3_client.upload_file(local_path, BUCKET_NAME, s3_key)
        logging.debug(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –≤ S3 –∫–∞–∫ {s3_key}")
    except Exception as e:
        logging.exception("üí• –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ S3")

if __name__ == "__main__":
    logging.debug("üõ† main() –≤ logger.py –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è")
    upload_to_s3_manual()
